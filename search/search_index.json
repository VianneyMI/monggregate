{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#overview","title":"Overview","text":"<p>Monggregate is a library that aims at simplifying usage of MongoDB aggregation pipelines in python. It is based on MongoDB official python driver, pymongo and on pydantic.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>provides an OOP interface to the aggregation pipeline.</li> <li>allows you to focus on your requirements rather than MongoDB syntax</li> <li>integrates all the MongoDB documentation and allows you to quickly refer to it without having to navigate to the website.</li> <li>enables autocompletion on the various MongoDB features.</li> <li>offers a pandas-style way to chain operations on data.</li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<p>This package requires python &gt; 3.10, pydantic &gt; 1.8.0</p>"},{"location":"#installation","title":"Installation","text":"<p>The repo is now available on PyPI:</p> <pre><code>pip install monggregate\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>The below examples reference the MongoDB sample_mflix database</p>"},{"location":"#basic-pipeline-usage","title":"Basic Pipeline usage","text":"<pre><code>import os\nfrom dotenv import load_dotenv \nimport pymongo\nfrom monggregate import Pipeline, S\n# Creating connexion string securely\n# You need to create a .env file with your password\nload_dotenv(verbose=True)\nPWD = os.environ[\"MONGODB_PASSWORD\"] \nMONGODB_URI = f\"mongodb+srv://dev:{PWD}@myserver.xciie.mongodb.net/?retryWrites=true&amp;w=majority\"\n# Connect to your MongoDB cluster:\nclient = pymongo.MongoClient(MONGODB_URI)\n# Get a reference to the \"sample_mflix\" database:\ndb = client[\"sample_mflix\"]\n# Creating the pipeline\npipeline = Pipeline()\n# The below pipeline will return the most recent movie with the title \"A Star is Born\"\npipeline.match(\ntitle=\"A Star Is Born\"\n).sort(\nby=\"year\"\n).limit(\nvalue=1\n)\n# Executing the pipeline\ncurosr = db[\"movies\"].aggregate(pipeline.export())\n# Printing the results\nresults = list(curosr)\n#print(results) # Uncomment to see the results\n</code></pre>"},{"location":"#advanced-usage-with-mongodb-operators","title":"Advanced usage, with MongoDB operators","text":"<pre><code>import os\nfrom dotenv import load_dotenv \nimport pymongo\nfrom monggregate import Pipeline, S\n# Creating connexion string securely\nload_dotenv(verbose=True)\nPWD = os.environ[\"MONGODB_PASSWORD\"]\nMONGODB_URI = f\"mongodb+srv://dev:{PWD}@myserver.xciie.mongodb.net/?retryWrites=true&amp;w=majority\"\n# Connect to your MongoDB cluster:\nclient = pymongo.MongoClient(MONGODB_URI)\n# Get a reference to the \"sample_mflix\" database:\ndb = client[\"sample_mflix\"]\n# Creating the pipeline\npipeline = Pipeline()\npipeline.match(\nyear=S.type_(\"number\") # Filtering out documents where the year field is not a number\n).group(\nby=\"year\",\nquery = {\n\"movie_count\":S.sum(1), # Aggregating the movies per year\n\"movie_titles\":S.push(\"$title\")\n}\n).sort(\nby=\"_id\",\ndescending=True\n).limit(10)\n# Executing the pipeline\ncursor = db[\"movies\"].aggregate(pipeline.export())\n# Printing the results\nresults = list(cursor)\n#print(results)\n</code></pre>"},{"location":"#even-more-advanced-usage-with-expressions","title":"Even more advanced usage with Expressions","text":"<pre><code>import os\nfrom dotenv import load_dotenv \nimport pymongo\nfrom monggregate import Pipeline, S, Expression\n# Creating connexion string securely\nload_dotenv(verbose=True)\nPWD = os.environ[\"MONGODB_PASSWORD\"]\nMONGODB_URI = f\"mongodb+srv://dev:{PWD}@myserver.xciie.mongodb.net/?retryWrites=true&amp;w=majority\"\n# Connect to your MongoDB cluster:\nclient = pymongo.MongoClient(MONGODB_URI)\n# Get a reference to the \"sample_mflix\" database:\ndb = client[\"sample_mflix\"]\n# Using expressions\ncomments_count = Expression.field(\"comments\").size()\n# Creating the pipeline\npipeline = Pipeline()\npipeline.lookup(\nright=\"comments\",\nright_on=\"movie_id\",\nleft_on=\"_id\",\nname=\"comments\"\n).add_fields(\ncomments_count=comments_count\n).match(\nexpression=comments_count&gt;2\n).limit(1)\n# Executing the pipeline\ncursor = db[\"movies\"].aggregate(pipeline.export())\n# Printing the results\nresults = list(cursor)\n#print(results)\n</code></pre>"},{"location":"api/","title":"Api","text":"<p>:::monggregate.pipeline    options:      annotations_path: source</p>"},{"location":"changelog/","title":"Release Notes","text":""},{"location":"changelog/#0160","title":"0.16.0","text":""},{"location":"changelog/#new-features","title":"New Features","text":"<ul> <li>Created S object (represents $ sign since it is not a valid variable name in python) to store all MongoDB operators and to create references to fields</li> <li>Created SS object (represents $$) to store aggregation variables and referenes to user variables</li> <li>Interfaced a chunk of new operators(add, divide, multiply, pow, substract, cond, if_null, switch, millisecond, date_from_string, date_to_string, type_)</li> <li>Integrated new operators in Expressions class</li> </ul>"},{"location":"changelog/#refactoring","title":"Refactoring","text":"<ul> <li>Redefined Expressions completely. Simplified and clarified how they can be used when using this package.</li> <li>Removed index module that was at the root of the package (monggregate.index.py -&gt; \u00f8) </li> <li>Removed expressions subpackage (monggregate.expression -&gt; \u00f8)</li> <li>Moved expressions fields module to the root of the package (monggregate.expressions.fields.py -&gt; monggregate.fields.py)</li> <li>Removed expressions aggregation_variables module (monggregate.expression.aggregation_variables.py -&gt; \u00f8)</li> <li>Moved the enums that were defined in index to a more relevant place. Ex OperatorEnum is now in monggregate.operators.py</li> </ul>"},{"location":"changelog/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>Operators now return python objects rather than expressions/statements.    NOTE: The wording might change for clarification purposes.         statement might be renamed expression and resolve might renamed express         To do so, some arguments might need to be renamed in the operators</li> <li>Expressions subpackage has been exploded and some parts have been deleted</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>Updated readme to reflect changes in the packge. Readme now focuses on the recommended way to use the package and clarifies how to use MongoDB operators.</li> </ul>"},{"location":"changelog/#0150","title":"0.15.0","text":""},{"location":"changelog/#fixes","title":"Fixes","text":"<ul> <li>Fixed bug in <code>Search.from_operator()</code> classmethod due to recent change in operator type in <code>Search</code> class</li> <li>Fixed misspelled operators in constructors map in <code>Search</code> class</li> <li>Fixed missing aliases and missing kwargs reduction in some <code>Search</code> operators</li> </ul>"},{"location":"changelog/#0141","title":"0.14.1","text":""},{"location":"changelog/#fixes_1","title":"Fixes","text":"<ul> <li>Fixed autocompletion</li> </ul>"},{"location":"changelog/#refactoring_1","title":"Refactoring","text":"<ul> <li>Import pydantic into base.py and using base.py to access pydantic features</li> </ul>"},{"location":"changelog/#0140","title":"0.14.0","text":""},{"location":"changelog/#upgrades","title":"Upgrades","text":"<ul> <li>Make package compatible with pydantic V2</li> </ul>"},{"location":"changelog/#refactoring_2","title":"Refactoring","text":"<ul> <li>Use an import trick to still use pydantic V1 even on environments using pydantic V2</li> <li>Centralized pydantic import into base.py in order to avoid having to use import trick on multiple files</li> </ul>"},{"location":"changelog/#documentation_1","title":"Documentation","text":"<ul> <li>Updated readme to better reflect current state of the pacakge.</li> <li>Started a changelog ! :champagne:</li> <li>Major change in the doc </li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>We are actively looking for new contributors and maintainers to help us.</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>If you find a bug or have feature suggestions please raise an issue.</p>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<p>We welcome pull requests from everyone. Follow the steps below to contribute to this project. The maintainers currently use GitHub to handle the roadmap of the project. So if you want to contribute to the code base, you can either:</p> <ul> <li>create an issue to start a discussion about a feature idea or a bug</li> <li>address an issue already listed in our backlog</li> </ul>"},{"location":"contributing/#new-to-open-source","title":"New to Open Source?","text":"<p>Please check out this article to help you get started.</p>"},{"location":"how-to/setup/","title":"Get Data","text":"<p>This guide will show you how to setup an Atlas Cluster and download sample data to follow the tutorial and play with monggregate.</p>"},{"location":"how-to/setup/#instructions","title":"Instructions","text":"<p>1. The first step is to create an Atlas account (if you do not have one already). You can do it here. Simply fill the form and click on \"Create your Atlas account\". You can even sign up with Google.</p> <p>2. Once your account is created, you will to create a free tier cluster. Click on \"Build a Database\" and follow the steps. Select the M0 free cluster.  You can choose the cloud provider and the region that yout want. Name your cluster as pleased and click on \"Create Cluster\". </p> <p>3. Once your cluster is created, you will need to create a database user and whitelist your ip. You should be redirected to a security quickstart page guiding you to create a database user and adding your IP address to the IP access whitelist.</p> <p>4. Click on the three dots next to Browse Collections and then on \"Load Sample Dataset\". This might take a few minutes.</p> <p>5. You are now ready to follow the tutorial. You can find the first page here. You should now see the following databases when clicking on \"Browse Collections\".</p> <ul> <li><code>sample_airbnb</code></li> <li><code>sample_analytics</code></li> <li><code>sample_geospatial</code></li> <li><code>sample_guides</code></li> <li><code>sample_mflix</code></li> <li><code>sample_restaurants</code></li> <li><code>sample_supplies</code></li> <li><code>sample_training</code></li> <li><code>sample_weatherdata</code></li> </ul>"},{"location":"how-to/setup/#references","title":"References","text":"<ul> <li>This video shows the above steps.</li> <li>This guide briefly encompasses the above steps and goes a step further by showing you how to connect to your database in python with pymongo.</li> </ul>"},{"location":"how-to/commons/combine-collections/","title":"Combine collections","text":"<p>This guide will show you how to merge two collections. Keep in mind that merging collections here means embedding documents from one collection into matching documents from another collection.</p> <p>In the previous guide, we splitted the <code>listingsAndReviews</code> collection into two collections: <code>listings</code> and <code>reviews</code>. We will use these two collections to show you how to merge collections.</p>"},{"location":"how-to/commons/combine-collections/#what-do-we-want-to-achieve","title":"What do we want to achieve ?","text":"<p>We want to get a listing and its associated reviews.</p>"},{"location":"how-to/commons/combine-collections/#how","title":"How ?","text":"<p>We will use the <code>$lookup</code> stage that was also presented in the tutorial.</p> <pre><code>#/!\\    /!\\    /!\\\n# Imports\n# and boilerplate code\n# to get the db object\n# are not included\n#/!\\    /!\\    /!\\\nfrom monggregate import Pipeline\nreviews = \"reviews\"\npipeline = Pipeline()\npipeline.lookup(\nright=reviews,\nleft_on=reviews,\nright_on=\"_id\",\nname=reviews\n)\ndb[\"listings\"].aggregate(pipeline=pipeline.export())\n</code></pre>"},{"location":"how-to/commons/create-or-update-a-collection/","title":"Create or Update a collection","text":"<p>This guide will show you how to create a new collection from an existing one and to update an existing collection.</p> <p>Like in the previous how-to guide, we will use the <code>listingsAndReviews</code> collection from the <code>sample_airbnb</code> database.</p>"},{"location":"how-to/commons/create-or-update-a-collection/#what-do-we-want-to-achieve","title":"What do we want to achieve ?","text":"<p>We want to separate the reviews from the listings and to create a new collection <code>reviews</code> that will contain all the reviews while keeping the relationship between the reviews and the listings.</p>"},{"location":"how-to/commons/create-or-update-a-collection/#how","title":"How ?","text":""},{"location":"how-to/commons/create-or-update-a-collection/#creating-the-new-collection","title":"Creating the new collection","text":"<p>It's going to be very similar to what we have done previously. Except that this time we will save the result of the pipeline in a new collection.</p> <pre><code># /!\\    /!\\    /!\\\n# Imports\n# and boilerplate code\n# to get the db object\n# are not included\n# /!\\    /!\\    /!\\\nfrom monggregate import Pipeline\n# Building the pipeline\nreviews = \"reviews\"\npipeline = Pipeline()\npipeline.unwind(\nreviews\n).replace_root(\nreviews\n).out(\nreviews\n)\n# Executing the pipeline\ndb[\"listingsAndReviews\"].aggregate(pipeline=pipeline.export())\n# This pipeline won't output anything\n</code></pre> <p>We now have created our reviews collection. However now the reviews live in two places. The <code>listingsAndReviews</code> collection and the <code>reviews</code> collection. In the <code>listingsAndReviews</code> collection, we want to keep only the reference to a given review in the reviews collection.</p>"},{"location":"how-to/commons/create-or-update-a-collection/#updating-the-listingsandreviews-collection","title":"Updating the listingsAndReviews collection","text":"<p>We want to replace the listingsAndReviews collection with a new one that will contain the reference to the reviews instead of the full review documents.</p> <p>We have two options there, we can either create a new collection and drop the old one or we can update the existing collection.</p> <pre><code># /!\\    /!\\    /!\\\n# Imports\n# and boilerplate code\n# to get the db object\n# are not included\n# /!\\    /!\\    /!\\\nfrom monggregate import Pipeline\n# Useful variables\nnew_field = \"review_ids\"\nnew_collection = \"listings\"\nold_collection = \"listingsAndReviews\"\n# Building the pipeline\npipeline = Pipeline()\n# Showing Option 1: Creating a new collection \n# and dropping the old one\npipeline.add_fields(\n{new_field:\"$reviews._id\"}\n).add_fields(\n{\"reviews\":f\"${new_field}\"}\n).unset(\nnew_field\n).out(new_collection)\ndb.drop_collection(old_collection)\n# Showing Option 2: Updating the existing collection\n# pipeline.add_fields(\n#     {new_field:\"$reviews._id\"}\n#     ).add_fields(\n#         {\"reviews\":f\"${new_field}\"}\n#     ).unset(\n#         new_field\n#     ).out(old_collection)\n# db[old_collection].rename(new_collection)\n</code></pre> <p>You should now have two distinct collections: <code>reviews</code> and <code>listings</code>.</p> <p>Separating the reviews can be convenient to be able to retrieve a particular review document. Now you can do so, by querying the <code>reviews</code> collection with MQL. On the contrary, if you want to query a given listing with its reviews, you will have to perform a join operation using the aggregation framework.</p>"},{"location":"how-to/commons/create-or-update-a-collection/#generalization","title":"Generalization","text":"<p>The <code>$out</code> stage is very useful to create new collections or update existing ones. Alternatively, you can use the <code>$merge</code> stage to update an existing collection with more control on what happens in case of conflicts.</p>"},{"location":"how-to/commons/home/","title":"Home","text":"<p>The next pages, will show you some of the common use cases I faced and that led me to use the aggregation framework.</p>"},{"location":"how-to/commons/select-a-nested-document/","title":"Select a nested document","text":"<p>This guide will show you how to select and return nested documents directly.</p> <p>This is a common use case that one can face when working with a collection where relations are materialized by embedded documents.</p> <p>We will use the <code>listingsAndReviews</code> collection from the <code>sample_airbnb</code> database.</p> <p>This collection represent AirBnB listings.  The <code>reviews</code> do not have their own collection, they are embedded in a <code>reviews</code> field in the <code>listingsAndReviews</code> collection.</p>"},{"location":"how-to/commons/select-a-nested-document/#what-do-we-want-to-achieve","title":"What do we want to achieve ?","text":"<p>We want to select all the reviews of a given reviewer.</p>"},{"location":"how-to/commons/select-a-nested-document/#how","title":"How ?","text":"<p>This can be achieved by combining three stages:</p> <ul> <li><code>$unwind</code> to deconstruct the <code>reviews</code> array</li> <li><code>$replaceRoot</code> to promote the <code>reviews</code> field to the root of the document</li> <li><code>$match</code> to select the documents that match the given reviewer</li> </ul> <p>Thus the following pipeline will return all the reviews of the reviewer with the <code>reviewer_id:2961855</code>:</p> <pre><code># /!\\    /!\\    /!\\\n# Imports\n# and boilerplate code\n# to get the db object \n# are not included\n# /!\\    /!\\    /!\\\n# The reviewer_id whose reviews we want to retrieve\nreviewer_id = \"2961855\"\n# Building the pipeline\npipeline = Pipeline()\npipeline.unwind(\n\"reviews\"\n).replace_root(\n\"reviews\"\n).match(\nreviewer_id=reviewer_id\n)\n# Executing the pipeline\ncursor = db[\"listingsAndReviews\"].aggregate(pipeline=pipeline.export())\ndocuments = list(cursor)\n</code></pre> <p><code>documents[0]</code> should output:</p> <pre><code>{\n'_id': '197072826',\n'date': datetime.datetime(2017, 9, 24, 4, 0),\n'listing_id': '18776184',\n'reviewer_id': '2961855',\n'reviewer_name': 'Uge',\n'comments': 'Our stay at Alfredo\u2019s place was amazing. \\n\\nThe place is spacious, very clean, comfortable, decorated with good taste, and has everything one may need. I really liked his apartment. \\n\\nIt is very well located, the restaurants and bars around are great and in an easy 30 minute walk you are downtown or in old Montreal. Very pleasant area to be outside and felt very safe. \\n\\nAlfredo always answered my messages within 5 minutes and was incredibly helpful and generous. \\n\\nI highly recommend this place. Thank you Alfredo!'\n}\n</code></pre>"},{"location":"how-to/commons/select-a-nested-document/#generalization","title":"Generalization","text":"<p>This section aims at helping you adapt the above example to your own use case.</p> <p>First, the <code>unwind</code> stage above is not required in case of a one-to-one embedding relation.  For example, each listing has an <code>address</code> field that contains the address of the listing. In this case, you can directly use the <code>address</code> field in the <code>replace_root</code> stage. You do not need an <code>unwind</code> stage there because the <code>address</code> field is not an array.</p> <p>Second, the documents could be more deeply nested. In that case, you would need to repeat the above steps for each level of nesting. </p>"},{"location":"intro/mongodb-aggregation-framework/","title":"MongoDB Aggregation Framework","text":"<p>The MongoDB Aggregation Framework is an essential tool for any developer working with MongoDB. It offers advanced querying capabilities that are not available in MQL.</p>"},{"location":"intro/mongodb-aggregation-framework/#usage","title":"Usage","text":"<p>Even if the name focuses on the aggregation part of the framework, it can actually be used for the following purposes:</p> <ol> <li> <p>Data Summarization and Reporting:</p> <p>This the actual aggregation in \"aggregation framework\".</p> <p>The aggregation framework allows you to categorize data, group documents, calculate aggregated values like totals, averages, counts, and more, with stages like <code>$group</code>, <code>$count</code>, <code>$bucket</code>, <code>$bucketAuto</code>, <code>$facet</code>, <code>$sortBycount</code>.</p> </li> <li> <p>Data Transformation and Enrichment:</p> <p>This is one of the lesser know use case of the framework.</p> <p>It can be used to apply complex transformations to your data, and enrich existing documents with additional information. The main \"functions\" to do so are <code>$addFields</code>, <code>$densify</code>, <code>$fill</code>, <code>$replaceWith</code>, <code>$merge</code>, <code>$out</code>.</p> <p>You can see examples of this in Create or update a collection.</p> </li> <li> <p>Join-like Operations:</p> <p>Another important feature is the ability to perform join-like operations on your data.</p> <p>The frameworks exposes several functions to combine data from multiple collections. You can combine collections horizontally or vertically respectively with the <code>$lookup</code> and $unionWith stages.</p> <p>See Merge collections for some examples.</p> </li> <li> <p>Time Series Analysis:</p> <p>The framework also defines several operators that can be used to enhance some of the stages mentioned above.</p> <p>Among those operators, a couple of them are specifically designed to work with time series data. You can use them to group documents by time intervals, and to perform calculations on those groups.</p> <p>Such operators include <code>$dateAdd</code>, <code>$dateDiff</code>, <code>$millisecond</code>, <code>$toDate</code>, <code>$dateFromString</code>, <code>$dateFromParts</code> and much more.</p> <p> <li> <p>Geospatial Analysis:</p> <p>Similarly, the framework has capabilities to perform geospatial analysis on your data. </p> <p>In particular, you can compute distances between points, and find documents within a certain distance of a given point with the <code>$geoNear</code> stage.</p> </li> <li> <p>Textual Search and Analysis:</p> <p>Finally, one of the most interesting feature of the framework (and also one of the less expected from the name) is textual search.</p> <p>This part could be viewed as a framework on his own but, for some reason, was integrated to the aggregation framework. The aggregation framework leverages MongoDB Atlas full-text search capabilities. Textual search, unlike string matching, which looks for exact matches of a query term, involves finding documents that contain the query term or a related term.</p> <p>The entry points for this feature are the <code>$search</code> and <code>$searchMeta</code> stages. However, the reason I said this part could be viewed as a framework on his own previously is that <code>$search</code> and <code>$searchMeta</code> come with their own set operators. Such operators include <code>$autocomplete</code>, <code>$facet</code>, <code>$text</code>, <code>$compound</code> and much more.</p> <p>"},{"location":"intro/mongodb-aggregation-framework/#concepts","title":"Concepts","text":"<p>The previous section make references to several key concepts that are important to understand in order to use the aggregation framework. This section will introduce those concepts and explain them in more details.</p>"},{"location":"intro/mongodb-aggregation-framework/#stage","title":"Stage","text":"<p>A stage is an operation on your data. It can be a querying operation, an aggregation, a transformation, a join, a textual search, a sorting operation, etc. You can view it as a function.</p> <p>Stages are the building blocks of an aggregation pipeline. Each stage represents a specific data processing operation that is applied to a set of documents. These stages are arranged in a sequence to achieve the desired transformation of the data.</p>"},{"location":"intro/mongodb-aggregation-framework/#pipeline","title":"Pipeline","text":"<p>A pipeline is a set of stages that are executed in sequence. The output of a stage is the input of the next stage.  The output of the last stage is the output of the pipeline. The input of the first stage in a pipeline are the entire set of documents of the collection targeted by the pipeline.</p>"},{"location":"intro/mongodb-aggregation-framework/#operator","title":"Operator","text":"<p>Operators are the tools used within each stage to perform specific operations on the data. They allow for a wide range of computations, transformations, and evaluations. Examples of operators include arithmetic operators, logical operators, array operators, and more.</p>"},{"location":"intro/mongodb-aggregation-framework/#expression","title":"Expression","text":"<p>Probably the most difficult concept to grasp is the concept of expression. It is also the most important one.</p> <p>Expressions are a bit hard to define. They are actually not even properly defined in the official MongoDB documentation. Here how they are referred to in their documentation:</p> <p>Expressions can include field paths, literals, system variables, expression objects, and expression operators. Expressions can be nested.</p> <p>The reason why it is hard to define an expression is because the concepts of expression and operator are closely related (but still distinct).</p> <p>NOTE: In fact, operators produce expressions.</p> <p>An expression is a more general term that refers to a combination of values, variables, and operators that, when evaluated, results in a single value or object. An expression can include one or more operators to perform computations or transformations.</p>"},{"location":"intro/mongodb-umbrella/","title":"MongoDB Umbrella","text":"<p>MongoDB has developed one of the most complete database management system of the market.</p> <p>Altough it is mainly known for being a document-oriented NoSQL database with optional schemas. It has evolved and expanded to offer a wide range of features and services around data management. </p> <p>However here we will focus on the database itself and in particular its query languages.</p>"},{"location":"intro/mongodb-umbrella/#mql","title":"MQL","text":"<p>MQL stands for MongoDB Query Language. It is the language used to query MongoDB databases. It is a JSON-based query language that allows you to query documents in a collection.</p> <p>MQL allows to perform CRUD operations, that is inserting (Create), querying (Read), updating (Update) and deleting (Delete) documents in a collection.</p> <p>In the context of an application or web service, MQL would typically be used through a driver or an Object Document Mapper (ODM). The official MongoDB driver for Python is PyMongo. It is a low-level driver that allows you to interact with MongoDB databases. And two of the most popular ODM are MongoEngine and Beanie.</p> <p>MQL is not the main topic of monggregate nor this documentation, which is about the aggregation framework.</p>"},{"location":"intro/mongodb-umbrella/#aggregation-framework","title":"Aggregation Framework","text":"<p>Quickly after the release of MongoDB, the MongoDB team realized that the query language was not sufficient to perform complex queries.</p> <p>In particular, there was a gap to do analytics on the data like it is easily done in SQL. </p> <p>Hence the release of Aggregation Framework later on. </p> <p>As I stated in my article</p> <p>Aggregation pipelines are the tool that allow MongoDB databases to really rival their SQL counterparts.</p> <p>The pymongo driver nor the ODMs mentioned above offer a way to easily use the aggregation framework. They only let you do your aggregation queries as raw strings.</p> <p>This is where <code>monggregate</code> comes in. <code>monggregate</code> exposes an OOP interface to the aggregation framework that make it easier to build pipelines.</p> <p>In the following page, we will do a deep-dive on the aggregation framework.</p>"},{"location":"intro/mongodb-umbrella/#atlas-search","title":"Atlas Search","text":"<p>Atlas Search  is a full-text search service that is fully integrated with MongoDB Atlas. It allows you to perform text search on your data and is based on Apache Lucene.</p> <p>As Atlas Search is a part of the aggregation framework, <code>monggregate</code> also offers a way to use it.</p>"},{"location":"intro/mongodb-umbrella/#other-stuffs","title":"Other stuffs","text":"<p>MongoDB also offers capabilities for time series collections, semantic and vector search and probably much more that may or may not be integrated in monggregate in the future.</p> <p>But, as of today, these features are not in the scope of <code>monggregate</code>.</p>"},{"location":"intro/why-use-monggregate/","title":"Why use Monggregate ?","text":"<p>In this page, we will present the various reasons one may want to use <code>monggregate</code>.</p>"},{"location":"intro/why-use-monggregate/#what-monggregate-is","title":"What monggregate is ?","text":"<p>As a disclaimer, I'll start by saying what <code>monggregate</code> is not.</p> <p><code>monggregate</code> IS NOT a MongoDB driver NOR an Object Document Mapper (ODM).</p> <p><code>monggregate</code> can be seen as a NoSQL query builder for MongoDB.</p> <p>If you are not familiar with the concept of query builder, I suggest you watch this video from Arjan Codes where he explains the difference between using raw SQL, query builders and ORMs. Even if the examples use SQL, there are still relevant in a NoSQL context.</p>"},{"location":"intro/why-use-monggregate/#why-use-monggregate","title":"Why use monggregate ?","text":"<p>With that said, when or why would one want to use <code>monggregate</code> ? As written in the previous page, the aggregation framework can be used for data analytics, data transformation and much more.</p> <p>However, it is not convenient to use with the available tools overall and in python in particular (even if MongoDB as recently [2023] tried to overcome this by releasing several helpers such as the stage wizard and a chat assistant to help building queries).</p> <p>The main critiques that we can have about the aggregation framework either about the framework itself or about its accesibility in python are the following:</p> <ul> <li>It has a steep learning curve</li> <li>It is quite verbose</li> <li>There is no python API to use it</li> <li>It is undocumented in pymongo</li> </ul> <p><code>monggregate</code> tries to solve these issues by providing a python API to use the aggregation framework.</p> <p>The API improves the readability of the pipelines and make the queries less verbose.</p> <p>It also integrates most of the official MongoDB documentation available directly in the code. Therefore, you no longer have to navigate between the documentation and your code. You no longer have to try your pipelines on Compass or Atlas to see if they work. You can do it directly in your application code. You could for example, try out your pipelines in a test suite or in a notebook.</p> <p>Cherry on the cake, your IDE will help you in the process because you now have autocompletion showing you the available stages and operators, their parameters, types, descriptions and restrictions.</p>"},{"location":"intro/why-use-monggregate/#who-should-use-it","title":"Who should use it ?","text":"<p>The package is probably more useful for data and sofware engineers that are not familiar with the aggregation framework or that are not familiar with MongoDB in general.</p> <p>However, developers that are already familiar with the aggregation framework or MongoDB may also find it useful as it can help them to build pipelines faster and with less errors. It can also improve the readability of the pipelines built.</p>"},{"location":"intro/why-use-monggregate/#how-to-use-it","title":"How to use it ?","text":"<p>In the following pages, we will see how to use <code>monggregate</code> to build aggregation pipelines.</p>"},{"location":"tutorial/getting-started/","title":"Getting Started","text":""},{"location":"tutorial/getting-started/#installing-monggregate","title":"Installing monggregate","text":"<p><code>monggregate</code> is available on PyPI:</p> <pre><code>pip install monggregate\n</code></pre>"},{"location":"tutorial/getting-started/#requirements","title":"Requirements","text":"<p>It requires python &gt; 3.10 and has a few required dependencies such as <code>pydantic</code>, <code>pyhumps</code> and <code>typing-extensions</code>.</p> <p>If it as a good query builder it helps you build the query, in order to execute them you will need a MongoDB driver.</p> <p>For more details about the requirements, see the requirements files in the repo. </p>"},{"location":"tutorial/getting-started/#first-steps","title":"First steps","text":"<p>There are several ways you may use monggregate.</p> <p>You can use the stages individually and build your pipeline step by step or you can use the <code>Pipeline</code> class to build your pipeline. That's actually the way I recommend you to use it.</p> <p>In that cases, your first steps will look like this:</p> <pre><code>from monggregate import Pipeline\npipeline = Pipeline()\n</code></pre> <p>Now when writing,</p> <pre><code>pipeline.\n</code></pre> <p>your IDE will show you the available stages.</p> <p>You should see something like this.</p> <p></p> <p>In the next page, we will see in more details how to use the <code>Pipeline</code> class.</p>"},{"location":"tutorial/operators/","title":"Operators","text":"<p>Operators are in a way the building blocks of stages.</p>"},{"location":"tutorial/operators/#stages-and-operators","title":"Stages and Operators","text":"<p>The relationship between operators and stages is similar to the relationship between stages and pipelines (but not exactly the same!).</p> <p>The first main difference is that operators are optional for stages. For example, the <code>Match</code> stage can be used without any operator.</p> <p>Conversely, some stages do not make a lot of sense if used without any operators. For example, the <code>Group</code> stage is not very useful by itself. It is meant to be used with operators to perform the actual aggregation.</p> <p>Another difference is that operators are not necessarily used sequantially, they can also be used in parallel. For example, the <code>Group</code> stage can be used with the <code>$sum</code> and <code>$push</code> operators at the same time, depending on the requirements.</p>"},{"location":"tutorial/operators/#compatibility","title":"Compatibility","text":"<p>Some operators are not meant to be used with some stages. Others behave differently depending on the stage they are used in. Those compatibility rules are detailed in the documentation of each operator as monggregate documentation integrates a good part of the MongoDB documentation.  For example the <code>$mergeObjects</code> operator documentation clearly states that it can only be used in the following stages: <ul> <li><code>$bucket</code></li> <li><code>$bucketAuto</code></li> <li><code>$group</code></li> <li><code>$replaceRoot</code></li> </ul>"},{"location":"tutorial/operators/#usage","title":"Usage","text":"<p>Because of the above considerations, the usage of operators is a bit different than the usage of stages.</p> <p>You cannot access the operators through the stages, the same way you can access the stages through the pipeline (eventhough it's on our development roadmap).</p> <p>Therefore, you need to import the operators from the <code>monggregate.operators</code> namespace. Or you can use the <code>S</code> shortcut to access the operators. <code>S</code> is an object that includes all the operators as functions, like the <code>Pipeline</code> class includes all the stages as methods.  <p>Thus, the grouping example would become:</p> <pre><code>pipeline = Pipeline()\npipeline.group(\nby=\"year\",\nquery={\n\"movie_count\": S.sum(1),\n\"movie_titles\": S.push(S.field(\"title\"))\n}\n)\n</code></pre>"},{"location":"tutorial/operators/#list-of-available-operators-in-monggregate","title":"List of available operators in Monggregate","text":"<p>Currently, monggregate supports the following operators:</p> <ul> <li> <p>accumulators</p> <ul> <li><code>$avg</code></li> <li><code>$count</code></li> <li><code>$first</code></li> <li><code>$last</code></li> <li><code>$max</code></li> <li><code>$min</code></li> <li><code>$push</code></li> <li><code>$sum</code></li> </ul> </li> <li> <p>arithmetic</p> <ul> <li><code>$add</code></li> <li><code>$divide</code></li> <li><code>$multiply</code></li> <li><code>$pow</code></li> <li><code>$subtract</code></li> </ul> </li> <li> <p>array</p> <ul> <li><code>$arrayToObject</code></li> <li><code>$filter</code></li> <li><code>$first</code></li> <li><code>$in</code></li> <li><code>$isArray</code></li> <li><code>$last</code></li> <li><code>$max_n</code></li> <li><code>$min_n</code></li> <li><code>$size</code></li> <li><code>$sortArray</code></li> </ul> </li> <li> <p>boolean</p> <ul> <li><code>$and</code></li> <li><code>$not</code></li> <li><code>$or</code></li> </ul> </li> <li> <p>comparison</p> <ul> <li><code>$cmp</code></li> <li><code>$eq</code></li> <li><code>$gt</code></li> <li><code>$gte</code></li> <li><code>$lt</code></li> <li><code>$lte</code></li> <li><code>$ne</code></li> </ul> </li> <li> <p>conditional</p> <ul> <li><code>$cond</code></li> <li><code>$ifNull</code></li> <li><code>$switch</code></li> </ul> </li> <li> <p>date</p> <ul> <li><code>$millisecond</code></li> </ul> </li> <li> <p>object</p> <ul> <li><code>$mergeObjects</code></li> <li><code>$objectToArray</code></li> </ul> </li> <li> <p>strings</p> <ul> <li><code>$concat</code></li> <li><code>$dateFromString</code></li> <li><code>$dateToString</code></li> </ul> </li> <li> <p>search</p> <ul> <li>See search page</li> </ul> </li> </ul>"},{"location":"tutorial/operators/#disambiguation","title":"Disambiguation","text":"<p>Some operators have MQL homonyms (i.e. operators with the same name in MongoDB Query Language), that have a slightly different syntax or usage.</p> <p><code>$gte</code> is an example of such operator. Its syntax is not the same in an aggregation pipeline than in a MQL query.</p> <p>In a MQL query, you are going to use it as follows:</p> <pre><code>{\n\"year\": {\"$gte\": 2010}\n}\n</code></pre> <p>In an aggregation pipeline, you are going to use it as follows:</p> <pre><code>{\n\"$gte\": [\"$year\", 2010]\n}\n</code></pre> <p>At the opposite there are aggregation operators that can be used as-is in MQL queries."},{"location":"tutorial/pipeline/","title":"Pipelines","text":"<p>Pipelines are a key concept in the aggregation framework. Therefore, the  <code>Pipeline</code> class is also a central class in the package, as it is used to build and execute pipelines."},{"location":"tutorial/pipeline/#building-a-pipeline","title":"Building a pipeline","text":"<p> The <code>Pipeline</code> class includes a method for each stage of the aggregation framework. Each stage of the aggregation framework also has its own class in the package. And each <code>Stage</code> class has a mirror method in the <code>Pipeline</code>. For more information, see the stages page. <p>For example, the <code>Match</code> stage has a <code>match</code> method in the <code>Pipeline</code> class and calling <code>pipeline.match()</code> like in the code snippet below.</p> <pre><code>from monggregate import Pipeline\npipeline = Pipeline()\npipeline.match(title=\"A Star Is Born\")\n</code></pre> <p>will add a <code>Match</code> stage instance to the pipeline and return the pipeline instance.</p> <p>That way, you can chain the stages together to build your pipeline.</p> <pre><code>from monggregate import Pipeline\npipeline = Pipeline()\n# The below pipeline will return (when executed) \n# the most recent movie with the title \"A Star is Born\"\npipeline.match(\ntitle=\"A Star Is Born\"\n).sort(\nby=\"year\"\n).limit(\nvalue=1\n)\n</code></pre>"},{"location":"tutorial/pipeline/#executing-a-pipeline","title":"Executing a pipeline","text":"<p>So far, we have built our pipeline object. But what do we do with it?</p> <p><code>monggregate</code> offers a bilateral integration with the tool of your choice to execute the pipeline.</p> <p>Bilateral because you can either integrate your pipeline to your tool or your tool to into the pipeline. In the following examples, I'll use <code>pymongo</code> as at the end of the day <code>motor</code>, <code>beanie</code> and <code>mongoengine</code> all use <code>pymongo</code> under the hood.</p>"},{"location":"tutorial/pipeline/#passing-your-pipeline-to-your-tool","title":"Passing your pipeline to your tool","text":"<p>The <code>Pipeline</code> class has an <code>export</code> method that returns a list of dictionaries of raw MongoDB aggregation language, which is the format expected by <code>pymongo</code>.</p> <pre><code>import pymongo\nfrom monggregate import Pipeline, S\n# Setup your pymongo connexion\nMONGODB_URI = f\"insert_your_own_uri\"\nclient = pymongo.MongoClient(MONGODB_URI)\ndb = client[\"sample_mflix\"]\n# Create your pipeline\npipeline = Pipeline()\n# Build your pipeline\npipeline.match(\ntitle=\"A Star Is Born\"\n).sort(\nby=\"year\"\n).limit(\nvalue=1\n)\n# Execute your pipeline\ncurosr = db[\"movies\"].aggregate(pipeline.export())\nresults = list(curosr)\nprint(results)\n</code></pre>"},{"location":"tutorial/pipeline/#passing-your-tool-to-your-pipeline","title":"Passing your tool to your pipeline","text":"<p>The pipeline class also has <code>run</code> method, a <code>_db</code> and a <code>collection</code> attributes that you can set that make your pipelines callable and runnable by being aware of your database connexion. Thus, you could write the above example like this:</p> <pre><code>import pymongo\nfrom monggregate import Pipeline, S\n# Setup your pymongo connexion\nMONGODB_URI = f\"insert_your_own_uri\"\nclient = pymongo.MongoClient(MONGODB_URI)\ndb = client[\"sample_mflix\"]\n# Create your database aware pipeline\npipeline = Pipeline(_db=db, collection=\"movies\") \n# Build your pipeline\n# (This does not change)\npipeline.match(\ntitle=\"A Star Is Born\"\n).sort(\nby=\"year\"\n).limit(\nvalue=1\n)\n# Execute your pipeline\n# (The execution is simpler)\nresults = pipeline.run()\nprint(results)\n</code></pre> <p>It also has a <code>__call__</code> method, so you could  replace the last wto lines with:</p> <pre><code>results = pipeline()\nprint(results)\n</code></pre>"},{"location":"tutorial/pipeline/#how-to-choose","title":"How to choose ?","text":"<p>It is up to you to choose the method that suits you the best.  I personnaly use the first method for now. There are plans to replace the <code>_db</code> attribute by a <code>uri</code> attribute and make the database connexion happen under the hood, but it is not implemented yet. When it is the second method will become more appealing.</p>"},{"location":"tutorial/pipeline/#an-alternative-to-build-pipelines","title":"An alternative to build pipelines","text":"<p>Another way to build your pipeline is to access the stages classes directly. All the stages are accessible in the <code>monggregate.stages</code> namespace. As such, you could write the above example like this:</p> <p><pre><code>import pymongo\nfrom monggregate import Pipeline, stages\n# Setup your pymongo connexion\nMONGODB_URI = f\"insert_your_own_uri\"\nclient = pymongo.MongoClient(MONGODB_URI)\ndb = client[\"sample_mflix\"]\n# Prepare your stages\nmatch_stage = stages.Match(query={\"title\": \"A Star Is Born\"})\nsort_stage = stages.Sort(by=\"year\")\nlimit_stage = stages.Limit(value=1)\nstages = [match_stage, sort_stage, limit_stage]\n# Create your pipeline ready to be executed\npipeline = Pipeline(stages=stages)\n# Execute your pipeline\ncurosr = db[\"movies\"].aggregate(pipeline.export())\nresults = list(curosr)\nprint(results)\n</code></pre> Once again, it is a question of preferences. This approach might be more readable for some people, but it is also more verbose.</p> <p>Howevere, there are still a couple of other advantages with this approach:</p> <ul> <li>You can reuse the stages in multiple pipelines</li> <li>You can easily reorder the stages</li> </ul> <p>The second point is particularly relevant given the utilies function in the <code>Pipeline</code> class.</p>"},{"location":"tutorial/pipeline/#pipeline-utilities","title":"Pipeline utilities","text":"<p>The <code>Pipeline</code> class has a few utilities methods to help you build your pipeline.</p> <p>Indeed it implements most of the python list methods, so you do not have to access the stages attribute to perform list operations.</p> <p>In the examples above, <code>len(pipeline)</code> would return <code>3</code>.</p> <p>You could also for example append a stage to the pipeline like this:</p> <pre><code>pipeline.append(stages.Project(title=1, year=1))\n</code></pre> <p>You also have access to the <code>append</code>, <code>extend</code>, <code>insert</code>,  methods directly on the <code>pipeline</code> object."},{"location":"tutorial/search/","title":"Search","text":"<p>Coming soon !</p>"},{"location":"tutorial/stages/","title":"Stages","text":"<p>Stages are the building blocks of aggregation pipelines.</p> <p>We saw in the previous page two methods to compose stages to effectively build a pipeline:</p> <ul> <li>using the pipeline stages methods</li> <li>using the stages classes directly</li> </ul> <p>Repeating what was described previously:</p> <p>Each stage of the aggregation framework also has its own class in the package. And each <code>Stage</code> class has a mirror method in the <code>Pipeline</code>.</p> <p>There is actually an asterik to this. Monggregate does not yet provide an interface to all of the stages provided by MongoDB. It is a work in progress and the list of available stages will grow over time. If you want to contribute, please refer to the contributing guide.</p> <p>You can see the full list of stages provided by MongoDB here.</p>"},{"location":"tutorial/stages/#list-of-available-stages-in-monggregate","title":"List of available stages in Monggregate","text":"<p>The following table lists the stages that are currently available in monggregate:</p> <ul> <li><code>$addFields</code></li> <li><code>$bucket</code></li> <li><code>$bucketAuto</code></li> <li><code>$count</code></li> <li><code>$group</code></li> <li><code>$limit</code></li> <li><code>$lookup</code></li> <li><code>$match</code></li> <li><code>$merge</code></li> <li><code>$out</code></li> <li><code>$project</code></li> <li><code>$replaceRoot</code></li> <li><code>$replaceWith</code></li> <li><code>$sample</code></li> <li><code>$search</code></li> <li><code>$searchMeta</code></li> <li><code>$set</code></li> <li><code>$skip</code></li> <li><code>$sort</code></li> <li><code>$sortByCount</code></li> <li><code>$unionWith</code></li> <li><code>$unset</code></li> <li><code>$unwind</code></li> </ul>"},{"location":"tutorial/stages/#usage","title":"Usage","text":"<p><code>monggregate</code> aims at providing a simple and intuitive interface to the MongoDB aggregation framework. Even though, it tries as much as possible to stick by the MongoDB aggregation framework syntax, it also tries to provide alternative ways, reproducing the syntax of other tools that new Mongo users might be more familiar with such as SQL and Pandas.</p> <p>For example, in the <code>`$group</code> stage, the MongoDB aggregation framework expects the grouping field(s) to be provided in the <code>_id</code> key. However, <code>monggregate</code> allows you to provide the grouping field(s) in the <code>by</code> key instead.</p> <pre><code>pipeline = Pipeline()\npipeline.group(\nby=\"year\",\nquery={\n\"movie_count\": {\"$sum\": 1},\n\"movie_titles\": {\"$push\": \"$title\"}\n}\n)\n</code></pre> <p>Similarly, <code>monggregate</code> pipeline <code>lookup</code> method and <code>Lookup</code> class provide aliases for the orignal MongoDB arguments:</p> MongoDB Original Name Monggregate Original Name Monggregate Convenient Alias from from right localField local_field left_on foreignField foreign_field right_on as as name <p>Note here that the original names of the arguments were converted to snake_case to follow the Python convention. You cannot use the camelCase version of the arguments names here.</p> <p>You can therefore use any combination of arguments names from the two rightmost columns above to build your stage.</p> <pre><code>pipeline = Pipeline()\npipeline.lookup(\nright = \"comments\", # collection to join\nleft_on = \"_id\",  # primary key\nright_on = \"movie_id\", # foreign key\n# name of the field that will contain the matching documents\nname = \"related_comments\" \n)\n</code></pre> <p>When using the stages methods, you can sometimes omit to name the argument(s). We can for example complete the previous example as follows:</p> <p><pre><code>pipeline = Pipeline()\npipeline.lookup(\nright = \"comments\", \nleft_on = \"_id\", \nright_on = \"movie_id\",\nname = \"related_comments\" \n).sort(\n\"movie_count\"\n).limit(\n10\n)\n</code></pre> The arguments names (<code>by</code> and <code>value</code> respectively) for the <code>sort</code> and <code>limit</code> stages are ommited.</p>"},{"location":"tutorial/stages/#operators","title":"Operators","text":"<p>You might have noticed in the grouping example how we tell monggregate to perform operations on the groups. In the example, we used the <code>$sum</code> and <code>$push</code> operators.</p> <p>For more information about operators, check the next page.</p>"},{"location":"tutorial/stages/#come-back-later","title":"Come back later","text":"<p>At this stage of the tutorial, you should already have enough to play around with the aggregation framework and start building your own pipelines. If you read everything straight, you might want to check out the operators page later on.</p>"}]}